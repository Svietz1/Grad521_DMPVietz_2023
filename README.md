# Grad521_DMPVietz_2023
data management plan for grad521

DMP Part 1 
The research question I am trying to answer is what temperatures with regards to the wall temp and bulk sodium temp, the optical fiber temperature sensors will experience in a liquid sodium wire wrapped test section. There are two separate parts of my research, first is understanding what temperatures will be recorded by the fiber temperature sensors in the helical geometry vs what temperature they will be experiencing. Secondly, I will be conducting Computational Fluid Dynamics simulations to predict what temperatures will be experienced. Since there is no experimental data to validate against, I will be conducting a sensitivity analysis to understand what parameters the system is sensitive to.  This is to support the Sodium Flow Investigative Experiment (SOFIE) facility being built at OSU. This liquid sodium loop is being built to validate thermal hydraulic codes that will assist in licensing the Natrium reactor by terrapower. My project will help ensure that the data generated by the facility is accurate and the nature of what the data means is understood. 
I am using a few different types of data. Mostly I will be collecting temperature measurements from the optical fibers saved to a TSV file. I will be comparing them to Thermocouple temperature measurements also in a TSV format for the first part. The second part will consist of several different data types such as temperature, Nusselt number, Prandtl number. I am still not 100% sure of all the parameters that could be impactful for my system but they will be of the sort. There will be images of the simulations as well as plots on the mesh quality and temperature data. The first data types are experimental data, while the second data types are simulation data. The methods I will be using to collect data are a LUNA interrogator system for the optical fiber temperature measurements, a NI-DAQ system for the TC measurements, and star-ccm+ for the simulations.  With regards to the size of my data, The Thermocouple data is just two points sampled a few times a second so they are only on the order of a couple hundred MB maximum. The Optical fibers can measure hundreds of temperature points multiple times a second, so the data can exceed several GB for those datasets. My Star-ccm+ simulations are generally on the order of 20GB each, and I will be generating several dozen of them, so around 150-200GB of data, so only the base files will be uploaded.

Who is Responsible for the DMP?
 I am the one who is in charge of the DMP since it is not directly being assigned by partners in industry. I am a GRA so I assist in roles for building and facilitating the facility. This follows a very strict NQA-1 data requirements. Since my research is an area where I have identified to ensure that the facility produces quality data, I should be aware of the standards set by NQA-1. I will be performing a parametric study  which will have many different simulations with values changed slightly to understand the effects of certain factors. I have an excel file and have written notes about how I want to structure the file names to disseminate which test each file corresponds to. The data will likely be used by our partners to argue that their data is representative of what we think it is. The experimental part compares thermocouples and optical fiber temperature sensors. I have yet to identify exactly how I want to correlate the thermocouple values to the fiber values. I am the only person on the project so I have a document and notes describing the data management decisions I have made so somebody can feasibly figure out what everything is. My data is not protected because I am not allowed to know the export-controlled geometry of the test section we are building since I would have to sign an NDA. I am given numbers that are in the ballpark but there is nothing in the way of data that needs to be protected. It is unrestrictive. My data is currently stored on a drive called depot that my lab has. The NQA-1 system ensures that all data on the drive is backed up at least twice. This is part of the drive itself since the entire lab is generally NQA-1 certified. I would classify that redundancy as automatic. For the simulations, there are enough similar files that even losing one or two would just make me have to rerun a simulation and change a few values so I am not too worried about that. I think Depot creates two copies that can be accessed.
